{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from baggingPU import BaggingClassifierPU\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from utils import Spinner\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# dataframes\n",
    "df_ligands = pd.read_csv(\"../ligands.csv\", index_col=\"id\", usecols=[\"id\", \"SMILES\"])\n",
    "df_sequences = pd.read_csv(\"../sequences.csv\", index_col=0)\n",
    "df_binding = pd.read_csv(\"../lig2seq.csv\")\n",
    "\n",
    "spinner=Spinner()\n",
    "# hyperparams\n",
    "min_f_count = 4\n",
    "ngram_max = 3 # put this >8 when you have more resources\n",
    "max_features = 1000\n",
    "\n",
    "lig_num = 100\n",
    "sample_size = 1000\n",
    "estimators = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................................................|............................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "tfidf_sequence = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    analyzer='char',\n",
    "    stop_words=None,\n",
    "    ngram_range=(1,ngram_max),\n",
    "    min_df=min_f_count,\n",
    "    max_features=max_features\n",
    ")\n",
    "\n",
    "tfidf_ligand = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    analyzer='char',\n",
    "    stop_words=None,\n",
    "    ngram_range=(1,ngram_max),\n",
    "    min_df=min_f_count,\n",
    "    max_features=max_features\n",
    ")\n",
    "\n",
    "spinner.start()\n",
    "tfidf_sequence.fit(df_sequences[\"sequence\"].values)\n",
    "print(\"sequences trained tfidf success\")\n",
    "sys.stdout.write('\\r')\n",
    "tfidf_ligand.fit(df_ligands[\"SMILES\"].values)\n",
    "print(\"ligands trained tfidf success\")\n",
    "spinner.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(p: int=10000, q: int=2000):\n",
    "    data = pd.DataFrame(columns=[\"lig_id\", \"SMILES\", \"seq_id\", \"sequence\", \"binding\"])\n",
    "    df_binding_temp = df_binding.sample(1000)\n",
    "    data[\"lig_id\"] = df_binding_temp[\"lig\"].values\n",
    "    data[\"seq_id\"] = df_binding_temp[\"seq\"].values\n",
    "\n",
    "    while data.shape[0] < q:\n",
    "        d_temp = pd.DataFrame(columns=[\"lig_id\", \"SMILES\", \"seq_id\", \"sequence\", \"binding\"])\n",
    "        df_binding_temp = df_binding.sample(q-data.shape[0])\n",
    "        d_temp[\"lig_id\"] = df_binding_temp[\"lig\"].values\n",
    "        d_temp[\"seq_id\"] = df_binding_temp[\"seq\"].values\n",
    "        data = data.append(d_temp, ignore_index=True).drop_duplicates()\n",
    "    print(data.shape)\n",
    "\n",
    "    data2 = data.loc[1000:,:]\n",
    "    data = data.loc[:999,:]\n",
    "    print(data.shape)\n",
    "\n",
    "    i = 0\n",
    "    while data.shape[0] < p:\n",
    "        print(i, data.shape)\n",
    "        d_temp = pd.DataFrame(columns=[\"lig_id\", \"SMILES\", \"seq_id\", \"sequence\", \"binding\"])\n",
    "        lig_ids = np.random.choice(df_ligands.index.values, p-data.shape[0], replace=True)\n",
    "        seq_ids = np.random.choice(df_sequences.index.values, p-data.shape[0], replace=True)\n",
    "        d_temp[\"lig_id\"] = lig_ids\n",
    "        d_temp[\"seq_id\"] = seq_ids\n",
    "        data = data.append(d_temp, ignore_index=True).drop_duplicates()\n",
    "        i += 1\n",
    "    print(i, data.shape)\n",
    "\n",
    "    data.loc[:,\"binding\"] = 0\n",
    "    data.loc[:749,\"binding\"] = 1\n",
    "    \n",
    "    data[\"SMILES\"] = data[\"lig_id\"].apply(lambda x: df_ligands.loc[df_ligands.index==x, \"SMILES\"].values[0])\n",
    "    data[\"sequence\"] = data[\"seq_id\"].apply(lambda x: df_sequences.loc[df_sequences.index==x, \"sequence\"].values[0])\n",
    "\n",
    "    data2[\"SMILES\"] = data2[\"lig_id\"].apply(lambda x: df_ligands.loc[df_ligands.index==x, \"SMILES\"].values[0])\n",
    "    data2[\"sequence\"] = data2[\"seq_id\"].apply(lambda x: df_sequences.loc[df_sequences.index==x, \"sequence\"].values[0])\n",
    "\n",
    "    return data, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5)\n",
      "(1000, 5)\n",
      "0 (1000, 5)\n",
      "1 (10000, 5)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test()\n",
    "\n",
    "X_a = tfidf_ligand.transform(train[\"SMILES\"].values).toarray()\n",
    "X_b = tfidf_sequence.transform(train[\"sequence\"].values).toarray()\n",
    "\n",
    "X_test_a = tfidf_ligand.transform(test[\"SMILES\"].values).toarray()\n",
    "X_test_b = tfidf_sequence.transform(test[\"sequence\"].values).toarray()\n",
    "\n",
    "X = np.concatenate((X_a, X_b), axis=1)\n",
    "X_test = np.concatenate((X_test_a, X_test_b), axis=1)\n",
    "y = train[\"binding\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................-"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  1.5min remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b................-"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quinn/Projects/LambdaSchool/BuildWeeks/PROTEIN/mocking/piping/baggingPU.py:593: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifierPU(DecisionTreeClassifier(), n_estimators=estimators, n_jobs=3, max_samples=sum(y), verbose=1)\n",
    "spinner.start()\n",
    "bc.fit(X, y)\n",
    "spinner.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_proba() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a83c858bbba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             df_sequences.sequence))\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-a83c858bbba5>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(ligid, seqid)\u001b[0m\n\u001b[1;32m      4\u001b[0m             df_ligands.SMILES), \n\u001b[1;32m      5\u001b[0m         tfidf_sequence.transform(\n\u001b[0;32m----> 6\u001b[0;31m             df_sequences.sequence))\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict_proba() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def predict(ligid: int, seqid: int) -> float: \n",
    "    lig_vec = tfidf_sequence.transform([df_sequences.iloc[5].sequence])\n",
    "    \n",
    "    return bc.predict_proba(\n",
    "        tfidf_ligand.transform(\n",
    "            df_ligands.SMILES), \n",
    "        tfidf_sequence.transform(\n",
    "            df_sequences.sequence))\n",
    "\n",
    "predict(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf_ligand.transform(df_ligands.iloc[0].SMILES)\n",
    "\n",
    "# tfidf_ligands.transform(df_ligands.SMILES)\n",
    "\n",
    "#tfidf_sequence.transform(df_sequences.sequence)\n",
    "\n",
    "#help(bc.predict_proba)\n",
    "xx = hstack([tfidf_sequence.transform([df_sequences.iloc[5].sequence]), \n",
    "               tfidf_ligand.transform([df_ligands.iloc[5].SMILES])], \n",
    "              ).toarray()\n",
    "\n",
    "bc.predict_proba(xx)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(ligid: int, seqid: int) -> float: \n",
    "    xx = hstack([tfidf_sequence.transform([df_sequences.iloc[seqid].sequence]), \n",
    "               tfidf_ligand.transform([df_ligands.iloc[ligid].SMILES])], \n",
    "              ).toarray()\n",
    "\n",
    "    return bc.predict_proba(xx)[0][0]\n",
    "\n",
    "predict(54325,5425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 predict_PROTOTYPE.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('predict_PROTOTYPE.pickle', 'wb') as pPp: \n",
    "    pickle.dump(predict, pPp)\n",
    "    \n",
    "!wc -c predict_PROTOTYPE.pickle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
